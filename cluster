#!/bin/bash

# is an error handler needed? for usage?
#trap 'handle_error $LINENO' ERR

# A simple script to help with cluster management
#
#   cluster status        - what's the status of the cluster (default)
#   cluster up            - bring the entire cluster
#   cluster down          - bring the entire cluster down
#   cluster rebuild       - rebuild and start the cluster
#   cluster backup        - make a backup of the cluster
#   cluster restore <tgz> - restore a cluster from the given backup .tgz file

# TODO add better usage
# TODO migrate vackup functions to this one
# TODO refactor backup package.
# TODO better way to check status in the container. what are the expected services? parse the compose
# TODO check for tools: docker, yq

### sudo snap install yq <-- INSTALL YQ via snap 

name=$(basename "$0")

# get the project name from parent dir
project_dir="$(cd -P -- "$(dirname -- "$0")" && pwd -P)"
project=$(basename "$project_dir")

# WARNING: Right now, cluster assumes PWD is in the same dir
project_file="docker-compose.yml"
#project_path=$project_dir/$project_file

# NOTE: remembering to type sudo gets me often.
DOCKER="sudo docker"

##
## Backup File Structure
##
# The backup file is created by: 'cluster backup'
# 1. Creating a new date-stamped dir from the parent-dir name (same as compose): name-YYYYMMDDHHMM
# 2. For each volume mentioned in the compose.yml
#   2.1 Run an empty container, with the volume and the backup dir mounted
#   2.2 Archive contents of volume: volume.tgz in the mounted backup dir
# 3. tar-gzip the entire backyp dir into name-YYYYMMDDHHMM.tgz
#
# Restoring the backup file with 'cluster restore backup-file.tgz'
# 1. Untar the backup file (into tmp?)
# 2. For each tgz file in the backup:
#   2.1 Confirm a matching entry in the compose file
#   2.2 ? Confirm a matching entry in container engine - note ability to re-home in new project
#   2.3 Run a simple container, mounting the volume and the backup
#   2.4 Import the backup into the volume with tar on the specific volume
# 3. Cleanup the backup dir (leaving the backup.tgz untouched)


cmd_export() {
    VOLUME_NAME="$1"
    FILE_NAME="$2"

    if [ -z "$VOLUME_NAME" ] || [ -z "$FILE_NAME" ]; then
        echo -e "Error: Not enough arguments"
        usage
    fi
    
    if ! $DOCKER volume inspect --format '{{.Name}}' "$VOLUME_NAME";
    then
        echo -e "Error: Volume $VOLUME_NAME does not exist"
        usage
    fi

# TODO: if FILE_NAME starts with / we need to error out
# unless we can translate full file paths

# Added redirect to dev/null. remove to debug

    if ! $DOCKER run --rm \
      -v "$VOLUME_NAME":/backup-volume \
      -v "$(pwd)":/backup \
      busybox \
      tar -zcf /backup/"$FILE_NAME" /backup-volume > /dev/null 2>&1 ;
    then
        echo "Error: Failed to start busybox backup container"
        exit 1
    fi

    echo "exported $VOLUME_NAME into $FILE_NAME"
}

cmd_import() {
    FILE_NAME="$1"
    VOLUME_NAME="$2"
    
    if [ -z "$VOLUME_NAME" ] || [ -z "$FILE_NAME" ]; then
        echo "Error: Not enough arguments"
        usage
    fi
    
    if ! $DOCKER volume inspect --format '{{.Name}}' "$VOLUME_NAME";
    then
        echo "Error: Volume $VOLUME_NAME does not exist"
        $DOCKER volume create "$VOLUME_NAME"
    fi

# TODO: check if file exists on host, if it does
# create a option for overwrite and check if that's set
# TODO: if FILE_NAME starts with / we need to error out
# unless we can translate full file paths    

    if ! $DOCKER run --rm \
      -v "$VOLUME_NAME":/backup-volume \
      -v "$(pwd)":/backup \
      busybox \
      tar -xzf /backup/"$FILE_NAME" -C / > /dev/null 2>&1 ; 
    then
        echo "Error: Failed to start busybox container"
        exit 1
    fi
    echo "imported $VOLUME_NAME, from $FILE_NAME"
}

cmd_backup() {
    # generate a datestamp for YYYYmmHHMM; the current time to the minute
	datestr="$(date +%Y%m%H%M)"
	backupdir="$project-$datestr"
	mkdir -p "$backupdir"
	
	# parse the project file to get the volume names
	yq e '.volumes | keys | .[]' $project_file | while read -r vol ; do
        # for each volume, export the volume to the
		volname="${project}_$vol"		
		target="$backupdir/$vol.tgz"
		cmd_export "$volname" "$target"
	done

    # finally, tar the tarfiles and remove the dir
    tarfile="$backupdir".tgz 
    tar -zcf "$tarfile" "$backupdir"
    rm -fr "$backupdir"
    echo backed-up "$project" to "$tarfile"
}

cmd_restore() {
	tarfile=$1

    # untar the tar file
    tar -xf "$tarfile"
    tardir=${tarfile%.*}

    # parse the project file to get the volume names
	yq e '.volumes | keys | .[]' $project_file | while read -r vol ; do
        # for each volume, import the target into the volume
		volname="${project}_$vol"		
		target="$tardir/$vol.tgz"
        cmd_import "$target" "$volname"
	done

    # cleanup the untar directory.
    rm -fr "$tardir"
    echo "restored $project from $tarfile"
}

# status - perform a status check on each container associated with the cluster
# 
# https://docs.docker.com/engine/reference/commandline/inspect/
# example json (snippit):
# --
# "State": {
#     "Status": "running",
#     "Running": true,
#     "Paused": false,
#     "Restarting": false,
#     "Dead": false,
#     "ExitCode": 0,
#     "Error": "",
#     "StartedAt": "2023-08-06T06:01:47.859267147Z",
#     "FinishedAt": "0001-01-01T00:00:00Z"
# },
# "Image": "redmine-redmine",
# "Labels": {
#    "com.docker.compose.container-number": "1",
#    "com.docker.compose.project": "redmine",
#    "com.docker.compose.project.config_files": "/home/philion/github/redmine/docker-compose.yml",
#    "com.docker.compose.project.working_dir": "/home/philion/github/redmine",
#    "com.docker.compose.service": "redmine"
# 
cmd_status() {
    # build an array of expected services from the project file
    expected=$(yq e '.services | keys | .[]' $project_file)

    # use 'docker compose ps --all' in the project dir to get all containers associated with the project
    # '-q' supresses the header and returns IDs instead of human-readable table
    $DOCKER compose ps --all -q | while read -r container ; do
        response=$(DOCKER inspect --type=container "$container" --format "{{.Labels.com.docker.compose.project.working_dir}} {{.Labels.com.docker.compose.service}} {{.State.Status}}")
        working_dir=${response[0]} # '{{.Labels.com.docker.compose.project.working_dir}}'
        service=${response[1]}     # '{{.Labels.com.docker.compose.service}}'
        status_str=${response[2]}  # '{{.State.Status}}'
        err=0
        # checks:
        # TODO '.Labels.com.docker.compose.project.working_dir' == $project_dir <-- same cluster/project
        # status == 'running'
        found="false" # using strings for human readability
        if [ "$status_str" == "running" ]; then
            # confirm working_dir us the same as project_dir
            if ! [ "$working_dir" != "$project_dir" ]; then
                echo -e "unexpected working_dir: $working_dir, expected $project_dir"
            fi

            # search for service in expected array
            for i in "${!expected[@]}"; do
                if [[ "${expected[$i]}" = "${service}" ]]; then
                    echo "$project $service $status_str" # all good, deeper status check/heartbeat?
                    # remove service from expected list
                    unset "expected[$i]" # quotes? really?
                    echo "$expected" # REMOVE
                    found="true"
                    break
                fi
            done
            if ! [ "$found" == "true" ]; then # FIXME check i vs array size?
                # the service was not found in the expected array
                echo -e "warning: unexpected $project $service, not in $project_file"
            fi
        else 
            # else dump '.State' for info
            # TODO - better state formatting
            fullstate=$(DOCKER inspect --type=container "$container" --format "{{.State}}")
            echo "$project $service ERROR: $fullstate"
            err=$((err+1)) # TODO should be list
        fi

        # check if expected services are missing, the $expected array should be empty
        if [ "${#expected[@]}" -gt 0 ]; then
            echo -e "expected services not found in $project: $expected"
            exit 1
        fi

        # check for errors
        if [ $err -gt 0 ]; then
            echo -e "errors found during status check ($err)"
            exit 1
        fi
	done
}

usage() {
    echo -e Unknown command: "$@"
    echo -e "Usage: $name {up|down|status|rebuild|backup|restore <tgz>}"
    exit 1
}


# make sure the compose yaml exists, and the working-dir is correct
cd "$project_dir" || exit 1
if ! [ -f "$project_file" ]; then
    echo -e Cannot fine $project_file.
    usage
fi

case "$1" in
    rebuild) $DOCKER compose down; $DOCKER --build -d ;;
    up)      $DOCKER compose up -d ;;
    down)    $DOCKER compose down ;;
    status)  cmd_status ;;
	backup)  cmd_backup ;;
	restore) cmd_restore "$2" ;;
    *)       usage "$@"
esac
