#!/bin/bash

# is an error handler needed? for usage?
#trap 'handle_error $LINENO' ERR

# A simple script to help with cluster management
#
#   cluster status        - what's the status of the cluster (default)
#   cluster up            - bring the entire cluster
#   cluster down          - bring the entire cluster down
#   cluster rebuild       - rebuild and start the cluster
#   cluster backup        - make a backup of the cluster
#   cluster restore <tgz> - restore a cluster from the given backup .tgz file

# TODO add better usage
# TODO migrate vackup functions to this one
# TODO refactor backup package.
# TODO better way to check status in the container. what are the expected services? parse the compose
# TODO check for tools: docker, yq

### sudo snap install yq <-- INSTALL YQ via snap 

name=$(basename "$0")

# get the project name from parent dir
project_dir="$(cd -P -- "$(dirname -- "$0")" && pwd -P)"
project=$(basename "$project_dir")

# WARNING: Right now, cluster assumes PWD is in the same dir
project_file="docker-compose.yml"
#project_path=$project_dir/$project_file

# NOTE: remembering to type sudo gets me often.
DOCKER="sudo docker"

#readonly true=1 false=0

##
## Backup File Structure
##
# The backup file is created by: 'cluster backup'
# 1. Creating a new date-stamped dir from the parent-dir name (same as compose): name-YYYYMMDDHHMM
# 2. For each volume mentioned in the compose.yml
#   2.1 Run an empty container, with the volume and the backup dir mounted
#   2.2 Archive contents of volume: volume.tgz in the mounted backup dir
# 3. tar-gzip the entire backyp dir into name-YYYYMMDDHHMM.tgz
#
# Restoring the backup file with 'cluster restore backup-file.tgz'
# 1. Untar the backup file (into tmp?)
# 2. For each tgz file in the backup:
#   2.1 Confirm a matching entry in the compose file
#   2.2 ? Confirm a matching entry in container engine - note ability to re-home in new project
#   2.3 Run a simple container, mounting the volume and the backup
#   2.4 Import the backup into the volume with tar on the specific volume
# 3. Cleanup the backup dir (leaving the backup.tgz untouched)


cmd_export() {
    VOLUME_NAME="$1"
    FILE_NAME="$2"

    if [ -z "$VOLUME_NAME" ] || [ -z "$FILE_NAME" ]; then
        echo -e "Error: Not enough arguments"
        usage
    fi
    
    if ! $DOCKER volume inspect --format '{{.Name}}' "$VOLUME_NAME";
    then
        echo -e "Error: Volume $VOLUME_NAME does not exist"
        usage
    fi

# TODO: if FILE_NAME starts with / we need to error out
# unless we can translate full file paths

# Added redirect to dev/null. remove to debug

    if ! $DOCKER run --rm \
      -v "$VOLUME_NAME":/backup-volume \
      -v "$(pwd)":/backup \
      busybox \
      tar -zcf /backup/"$FILE_NAME" /backup-volume > /dev/null 2>&1 ;
    then
        echo "Error: Failed to start busybox backup container"
        exit 1
    fi

    echo "exported $VOLUME_NAME into $FILE_NAME"
}

cmd_import() {
    FILE_NAME="$1"
    VOLUME_NAME="$2"
    
    if [ -z "$VOLUME_NAME" ] || [ -z "$FILE_NAME" ]; then
        echo "Error: Not enough arguments"
        usage
    fi
    
    if ! $DOCKER volume inspect --format '{{.Name}}' "$VOLUME_NAME";
    then
        echo "Error: Volume $VOLUME_NAME does not exist"
        $DOCKER volume create "$VOLUME_NAME"
    fi

# TODO: check if file exists on host, if it does
# create a option for overwrite and check if that's set
# TODO: if FILE_NAME starts with / we need to error out
# unless we can translate full file paths    

    if ! $DOCKER run --rm \
      -v "$VOLUME_NAME":/backup-volume \
      -v "$(pwd)":/backup \
      busybox \
      tar -xzf /backup/"$FILE_NAME" -C / > /dev/null 2>&1 ; 
    then
        echo "Error: Failed to start busybox container"
        exit 1
    fi
    echo "imported $VOLUME_NAME, from $FILE_NAME"
}

cmd_backup() {
    # generate a datestamp for YYYYmmHHMM; the current time to the minute
	datestr="$(date +%Y%m%H%M)"
	backupdir="$project-$datestr"
	mkdir -p "$backupdir"
	
	# parse the project file to get the volume names
	yq e '.volumes | keys | .[]' $project_file | while read -r vol ; do
        # for each volume, export the volume to the
		volname="${project}_$vol"		
		target="$backupdir/$vol.tgz"
		cmd_export "$volname" "$target"
	done

    # finally, tar the tarfiles and remove the dir
    tarfile="$backupdir".tgz 
    tar -zcf "$tarfile" "$backupdir"
    rm -fr "$backupdir"
    echo backed-up "$project" to "$tarfile"
}

cmd_restore() {
	tarfile=$1

    # untar the tar file
    tar -xf "$tarfile"
    tardir=${tarfile%.*}

    # parse the project file to get the volume names
	yq e '.volumes | keys | .[]' $project_file | while read -r vol ; do
        # for each volume, import the target into the volume
		volname="${project}_$vol"		
		target="$tardir/$vol.tgz"
        cmd_import "$target" "$volname"
	done

    # cleanup the untar directory.
    rm -fr "$tardir"
    echo "restored $project from $tarfile"
}

# status - perform a status check on each container associated with the cluster
# 
# https://docs.docker.com/engine/reference/commandline/inspect/
# example json (snippit):
# --
# "State": {
#     "Status": "running",
#     "Running": true,
#     "Paused": false,
#     "Restarting": false,
#     "Dead": false,
#     "ExitCode": 0,
#     "Error": "",
#     "StartedAt": "2023-08-06T06:01:47.859267147Z",
#     "FinishedAt": "0001-01-01T00:00:00Z"
# },
# "Image": "redmine-redmine",
# "Labels": {
#    "com.docker.compose.container-number": "1",
#    "com.docker.compose.project": "redmine",
#    "com.docker.compose.project.config_files": "/home/philion/github/redmine/docker-compose.yml",
#    "com.docker.compose.project.working_dir": "/home/philion/github/redmine",
#    "com.docker.compose.service": "redmine"
# 
# healthcheck, in docker compose: https://github.com/compose-spec/compose-spec/blob/master/spec.md#healthcheck
# healthcheck:
#   test: ["CMD", "curl", "-f", "http://localhost"]
#   interval: 1m30s
#   timeout: 10s
#   retries: 3
#   start_period: 40s
#   start_interval: 5s
#

# for a given container, healthcheck will return status information in human readable format
# if the status is completely valid, the first char will be a +, if down or errored a -, if unknown, a ?
healthcheck() {
    container="$1"
    #echo container=$container

    # given a container name (from project-service)
    found=false
    # $DOCKER container ls --filter="name=$container" -q | while read -r container_id ; do
    while read -r container_id ; do
        # see https://stackoverflow.com/questions/36439800/get-label-value-from-docker-inspect
        IFS=" " read -r -a response <<< "$($DOCKER inspect "$container_id" --format '{{index .Config.Labels "com.docker.compose.project.working_dir"}} {{index .Config.Labels "com.docker.compose.service"}} {{.State.Status}}')"
        
        working_dir=${response[0]} # {{index .Config.Labels "com.docker.compose.project.working_dir"}}
        service=${response[1]}     # {{index .Config.Labels "com.docker.compose.service"}}
        status_str=${response[2]}  # {{.State.Status}}

        # confirm status == 'running'
        if ! [ "$status_str" = "running" ]; then
            fullstate=$($DOCKER inspect "$container_id" --format "{{.State}}")
            # TODO better error state reporting, check healthcheck 1>&2
            echo "- $project $service: ERROR $fullstate"
        elif ! [ "$working_dir" = "$project_dir" ]; then
            # confirm working_dir us the same as project_dir
            echo "? $project $service: unexpected working_dir: $working_dir, expected $project_dir"
        else
            found=true
            echo "+ $project $service: $status_str" # all good, deeper status check/heartbeat?
        fi
	done < <( $DOCKER container ls --filter="name=$container" -q )
    # note: refactored loop based on https://stackoverflow.com/questions/34098271/bash-retain-variables-value-after-while-loop

    if ! $found; then
        # if it gets here, the container wasn't found
        echo "? $project $service: unable to find container for $container"
    fi
}

status_all() {
    yq e '.services | keys | .[]' $project_file | while read -r service ; do
        #echo checking $service
        result=$(healthcheck "$project-$service")
        echo "$result"
        # check first char for +,-,?
    done
}

usage() {
    echo -e Unknown command: "$@"
    echo -e "Usage: $name {up|down|status|rebuild|backup|restore <tgz>}"
    exit 1
}


# make sure the compose yaml exists, and the working-dir is correct
cd "$project_dir" || exit 1
if ! [ -f "$project_file" ]; then
    echo -e Cannot fine $project_file.
    usage
fi

# there's probably a better way to make status default
command="status"
if [ $# -gt 0 ]; then
    command=$1
fi
case "$command" in
    rebuild) $DOCKER compose down; $DOCKER --build -d ;;
    up)      $DOCKER compose up -d ;;
    down)    $DOCKER compose down ;;
    status)  status_all ;; #cmd_status ;;
	backup)  cmd_backup ;;
	restore) cmd_restore "$2" ;;
    *)       usage "$@"
esac
